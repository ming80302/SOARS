{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6599480d-aa4f-469c-9cd4-decfa08a93d2",
   "metadata": {},
   "source": [
    "two case studies of extreme precipitation during drought.\n",
    "\n",
    " - California Case Study – Event between October 19th -26th 2021\n",
    " (forecasts starting on Oct 1, 2021 and go out until Nov 30, 2021)\n",
    " \n",
    "lat_e = 43   <br>\n",
    "lat_s = 36   <br>\n",
    "lon_s = -125  <br>\n",
    "lon_e = -118  <br>\n",
    "\n",
    " - Southwest Monsoon Case Study – Event between July 20th – 27th 2021\n",
    "( use the forecasts starting on Jul 1, 2021 and go out until Aug 31, 2021.)\n",
    "Drought maps focus on Arizona, but I try to include as much of southwest AZ and New Mexico, therefore approximate boundaries are defined:\n",
    "\n",
    "lat_e = 37  <br>\n",
    "lat_s = 31  <br>\n",
    "lon_s = -115 <br>\n",
    "lon_e = -102  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7163e0-eb9a-4d2e-86c3-69eafe944db2",
   "metadata": {},
   "source": [
    "1) compute box-average PRISM data for the dates\n",
    "2) get ERA5 WTs for the dates\n",
    "\n",
    "3) compute box average ECMWF forecast daily precipitation for the dates (all ensemble members for a single forecast)\n",
    "4) get ECMWF forecast WTs for the dates (all ensemble members for a single forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb26fec-fc4e-44e8-8ea7-93cf4858cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633ef7b9-eaaa-440d-9f47-384b202f7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "# write PRISM domain averaged prec. timeseries to a flnm        \n",
    "def rw_prism_ts(date_s, date_e,lat_s, lat_e, lon_s, lon_e, flnm_o):\n",
    "    '''\n",
    "    date_s = date(2021, 10, 1)\n",
    "    date_e = date(2021, 11, 30)\n",
    "    lat_e = 43.\n",
    "    lat_s = 36.\n",
    "    lon_s = -125.\n",
    "    lon_e = -118.\n",
    "    '''\n",
    "    # create a range of dates list  \n",
    "    yyyymmdd = [dt.strftime(\"%Y%m%d\") for dt in daterange(date_s, date_e)]\n",
    "    n_day = len(yyyymmdd)\n",
    "\n",
    "    # and then convert it to datetime      \n",
    "    yyyymmdd_datetime = pd.to_datetime(yyyymmdd)\n",
    "    month_2 =yyyymmdd_datetime.month.values\n",
    "    day_2  = yyyymmdd_datetime.day.values\n",
    "    year_2 = yyyymmdd_datetime.year.values\n",
    "    year_2d = np.expand_dims(year_2, axis=1)\n",
    "    month_2d = np.expand_dims(month_2, axis=1)\n",
    "    day_2d = np.expand_dims(day_2, axis=1)\n",
    "    yyyymmdd_2d = np.concatenate((year_2d, month_2d, day_2d), axis = 1)\n",
    "    yyyymmdd_2d.shape\n",
    "    yyyymmdd_datetime_1d = np.expand_dims(yyyymmdd_datetime, axis=1)\n",
    "    \n",
    "    #compute box-average PRISM\n",
    "    dir_i = '/glade/campaign/mmm/c3we/prein/observations/PRISM/data/'\n",
    "    # The strftime() method returns a string representing date \n",
    "    year_s = date_s.strftime(\"%Y\")\n",
    "    flnm_prism = dir_i + 'PR/PRISM_daily_ppt_'+ str(year_s) + '.nc'\n",
    "    print(flnm_prism)\n",
    "\n",
    "    with xr.open_dataset(flnm_prism) as ds_prism:\n",
    "        prec_1d = ds_prism.PR.sel(time=slice(date_s.strftime(\"%Y-%m-%d\"), date_e.strftime(\"%Y-%m-%d\")), \\\n",
    "                              rlat=slice(lat_e, lat_s), rlon=slice(lon_s, lon_e)) \\\n",
    "                              .mean(dim=('rlat','rlon'))\n",
    "\n",
    "    # zip aggregates 2 1D lists to a tuple\n",
    "    prec_tuple = list(zip(yyyymmdd, prec_1d.values.tolist()))\n",
    "\n",
    "    # Writing a list of tuples to a text file \n",
    "    with open(flnm_o, 'w') as file:\n",
    "        for tuple in prec_tuple:\n",
    "            file.write('%s  %.2f \\n' % tuple)\n",
    "            \n",
    "# write ECMWF domain averaged prec. timeseries to a flnm        \n",
    "def rw_ecmwf_ts(date_s, date_e,lat_s, lat_e, lon_s, lon_e, flnm_o):\n",
    "    '''\n",
    "    date_s = date(2021, 10, 1)\n",
    "    date_e = date(2021, 11, 30)\n",
    "    lat_e = 43.\n",
    "    lat_s = 36.\n",
    "    lon_s = -125.\n",
    "    lon_e = -118.\n",
    "    '''\n",
    "    # create a range of dates list  \n",
    "    yyyymmdd = [dt.strftime(\"%Y%m%d\") for dt in daterange(date_s, date_e)]\n",
    "    n_day = len(yyyymmdd)\n",
    "\n",
    "    # and then convert it to datetime      \n",
    "    yyyymmdd_datetime = pd.to_datetime(yyyymmdd)\n",
    "    month_2 =yyyymmdd_datetime.month.values\n",
    "    day_2  = yyyymmdd_datetime.day.values\n",
    "    year_2 = yyyymmdd_datetime.year.values\n",
    "    year_2d = np.expand_dims(year_2, axis=1)\n",
    "    month_2d = np.expand_dims(month_2, axis=1)\n",
    "    day_2d = np.expand_dims(day_2, axis=1)\n",
    "    yyyymmdd_2d = np.concatenate((year_2d, month_2d, day_2d), axis = 1)\n",
    "    yyyymmdd_2d.shape\n",
    "    yyyymmdd_datetime_1d = np.expand_dims(yyyymmdd_datetime, axis=1)\n",
    "    dir_ecmwf = '/glade/campaign/mmm/c3we/ECMWF/'\n",
    "    yyyymm_s = date_s.strftime(\"%Y%m\")\n",
    "    flnm_ec = dir_ecmwf + str(yyyymm_s) + '/prec/prec_' + str(yyyymm_s)+ \".nc\" \n",
    "    print(flnm_ec)\n",
    "\n",
    "    n_mem = 50\n",
    "    with xr.open_dataset(flnm_ec) as ds_ec:\n",
    "        prec_t = ds_ec.TP_GDS0_SFC.sel(g0_lon_3=slice(lon_s, lon_e), g0_lat_2=slice(lat_e, lat_s))\n",
    "        prec = prec_t[:n_mem, 0:n_day, :,:].mean(dim=('g0_lat_2','g0_lon_3'))\n",
    "        #n_mem = prec.shape[0]\n",
    "\n",
    "\n",
    "    # m->mm\n",
    "    prec_2d = np.asarray(prec.transpose())*1000.\n",
    "    prec_daily_2d = np.ones((n_day,n_mem)) \n",
    "\n",
    "    # calculate daily prec. from Total precipitation\n",
    "    # because I started from the first one\n",
    "    prec_daily_2d[0,:] = prec_2d[0,:] \n",
    "    for nd in range(1,n_day):\n",
    "        prec_daily_2d[nd,:] = prec_2d[nd,:] - prec_2d[nd-1,:]  \n",
    "    \n",
    "    data_2d = np.concatenate((yyyymmdd_2d, prec_daily_2d), axis = 1)\n",
    "\n",
    "    fmt = '%i '*3 +' %1.2f'*n_mem\n",
    "    np.savetxt(flnm_o, data_2d, fmt=fmt)\n",
    "    \n",
    "#  get ERA5 WTs from  date_s, date_e\n",
    "def rw_era5WT_ts(date_s, date_e, flnm_o):\n",
    "    '''\n",
    "    date_s = date(2021, 10, 1)\n",
    "    date_e = date(2021, 11, 30)\n",
    "    '''\n",
    "    # create a range of dates list  \n",
    "    yyyymmdd = [dt.strftime(\"%Y%m%d\") for dt in daterange(date_s, date_e)]\n",
    "    n_day = len(yyyymmdd)\n",
    "\n",
    "    # and then convert it to datetime      \n",
    "    yyyymmdd_datetime = pd.to_datetime(yyyymmdd)\n",
    "    month_2 =yyyymmdd_datetime.month.values\n",
    "    day_2  = yyyymmdd_datetime.day.values\n",
    "    year_2 = yyyymmdd_datetime.year.values\n",
    "    \n",
    "    year_s = date_s.strftime(\"%Y\")\n",
    "    #flnm_wt = '/glade/work/mingge/WTing_existing-centroids/CONUS-WTs_1979-2019_PSL-UV700-TCW_12WTs_ERA5.cla'\n",
    "    flnm_wt = '/glade/campaign/mmm/c3we/mingge/COEXIST/ERA5/WT/CONUS-WTs_'+ str(year_s) + '.cla'\n",
    "    print(flnm_wt)\n",
    "\n",
    "    wts = pd.read_csv(flnm_wt, delimiter = '\\t', header=None, index_col=False, names=[\"year\", \"month\", \"day\",  \"wt\"])\n",
    "\n",
    "    rows = []\n",
    "    for nd in range(len(day_2)):\n",
    "        rows.append(wts[(wts['month']==month_2[nd]) & (wts['year']==year_2[nd]) &  (wts['day']==day_2[nd])].values)\n",
    "     \n",
    "    # rows is a list of numpy array, convert it to numpy array\n",
    "    rows_t = np.asarray(rows) #numpy.ndarray (62, 1, 4)\n",
    "    \n",
    "    # Writing np.array to a text file \n",
    "    with open(flnm_o, 'w') as file:\n",
    "        for row in rows_t:\n",
    "            # to avoid numpy array bracket\n",
    "            aa = ' '.join(map(str, row[0]))\n",
    "            file.write('%s \\n' % (aa))\n",
    "\n",
    "# get 50-member ECMWF WTs from  date_s, date_e            \n",
    "def rw_ecmwfWT_ts(date_s, date_e, flnm_o):\n",
    "    '''\n",
    "    date_s = date(2021, 10, 1)\n",
    "    date_e = date(2021, 11, 30)\n",
    "    '''\n",
    "    n_mem = 50\n",
    "    dir_wt = '/glade/campaign/mmm/c3we/mingge/COEXIST/ECMWF/WT/'\n",
    "    yyyymm_s = date_s.strftime(\"%Y%m\")\n",
    "\n",
    "    # and then convert it to datetime  \n",
    "    yyyymmdd = [dt.strftime(\"%Y%m%d\") for dt in daterange(date_s, date_e)]\n",
    "    yyyymmdd_datetime = pd.to_datetime(yyyymmdd)\n",
    "    month_2 =yyyymmdd_datetime.month.values\n",
    "    day_2  = yyyymmdd_datetime.day.values\n",
    "    year_2 = yyyymmdd_datetime.year.values\n",
    "    \n",
    "    for nm in range(1, n_mem+1):\n",
    "        flnm_wt = dir_wt + 'CONUS-WTs_' + yyyymm_s + '_' + \"{:02d}\".format(nm)+ '.cla'\n",
    "        #print(flnm_wt)\n",
    "        wts = pd.read_csv(flnm_wt, delimiter = '\\t', header=None, index_col=False, names=[\"year\", \"month\", \"day\",  \"wt\"])\n",
    "\n",
    "        rows = []\n",
    "        for nd in range(len(day_2)):\n",
    "            rows.append(wts[(wts['month']==month_2[nd]) & (wts['year']==year_2[nd]) &  (wts['day']==day_2[nd])].values)\n",
    "     \n",
    "        # rows is a list of numpy array, convert it to numpy array\n",
    "        rows_t = np.asarray(rows)\n",
    "        wt= rows_t[:,:,3] #(61, 1)\n",
    "     \n",
    "        if nm == 1:\n",
    "            print(flnm_wt)\n",
    "            data_all = np.squeeze(rows_t[:,:,:3]) #(61, 3)\n",
    "            \n",
    "        data_all = np.concatenate((data_all, wt), axis = 1) \n",
    "        fmt = '%4i'*(3+n_mem)  \n",
    "\n",
    "    # Writing np.array to a text file \n",
    "    np.savetxt(flnm_o, data_all, fmt=fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb09dcb7-f9a4-4962-8bf6-2943b184e055",
   "metadata": {},
   "source": [
    "### 1) compute box-average PRISM and ECMWF(51 members) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a5f94-44bc-46c9-9075-7670262f7abd",
   "metadata": {},
   "source": [
    " - California  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40a86eb-80f9-4bc4-a85d-29050380490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/campaign/mmm/c3we/prein/observations/PRISM/data/PR/PRISM_daily_ppt_2021.nc\n",
      "/glade/campaign/mmm/c3we/ECMWF/202110/prec/prec_202110.nc\n",
      "/glade/campaign/mmm/c3we/mingge/COEXIST/ERA5/WT/CONUS-WTs_2021.cla\n",
      "/glade/campaign/mmm/c3we/mingge/COEXIST/ECMWF/WT/CONUS-WTs_202110_01.cla\n"
     ]
    }
   ],
   "source": [
    "date_s = date(2021, 10, 1)\n",
    "date_e = date(2021, 11, 30)\n",
    "\n",
    "lat_e = 43.\n",
    "lat_s = 36.\n",
    "lon_s = -125.\n",
    "lon_e = -118.\n",
    "\n",
    "flnm_o = 'prec_prism_ca.txt'\n",
    "rw_prism_ts(date_s, date_e,lat_s, lat_e, lon_s, lon_e, flnm_o)\n",
    "\n",
    "flnm_o = 'prec_ecmwf_ca.txt'\n",
    "rw_ecmwf_ts(date_s, date_e,lat_s, lat_e, lon_s, lon_e, flnm_o)\n",
    "\n",
    "flnm_o = 'wt_era5_ca.txt'\n",
    "rw_era5WT_ts(date_s, date_e, flnm_o)\n",
    "\n",
    "flnm_o = 'wt_ecmwf_ca.txt'\n",
    "rw_ecmwfWT_ts(date_s, date_e, flnm_o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef5258d-9c3b-4466-9b97-e21a80122469",
   "metadata": {},
   "source": [
    " - Monsoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff7309b-a318-4369-9b68-276ea77aadf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/campaign/mmm/c3we/prein/observations/PRISM/data/PR/PRISM_daily_ppt_2021.nc\n",
      "/glade/campaign/mmm/c3we/ECMWF/202107/prec/prec_202107.nc\n",
      "/glade/campaign/mmm/c3we/mingge/COEXIST/ERA5/WT/CONUS-WTs_2021.cla\n",
      "/glade/campaign/mmm/c3we/mingge/COEXIST/ECMWF/WT/CONUS-WTs_202107_01.cla\n"
     ]
    }
   ],
   "source": [
    "date_s = date(2021, 7, 1)\n",
    "date_e = date(2021, 8, 31)\n",
    "\n",
    "lat_e = 37.\n",
    "lat_s = 31.\n",
    "lon_s = -115.\n",
    "lon_e = -102.\n",
    "\n",
    "flnm_o = 'prec_prism_monsoon.txt'\n",
    "rw_prism_ts(date_s, date_e,lat_s, lat_e, lon_s, lon_e, flnm_o)\n",
    "\n",
    "flnm_o = 'prec_ecmwf_monsoon.txt'\n",
    "rw_ecmwf_ts(date_s, date_e,lat_s, lat_e, lon_s, lon_e, flnm_o)\n",
    "\n",
    "flnm_o = 'wt_era5_monsoon.txt'\n",
    "rw_era5WT_ts(date_s, date_e, flnm_o)\n",
    "\n",
    "flnm_o = 'wt_ecmwf_monsoon.txt'\n",
    "rw_ecmwfWT_ts(date_s, date_e, flnm_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6c355-06c6-4fa2-93b4-e91186a51a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f3223-d6a8-4e21-b1f2-e0206d134c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff8e7e-5c87-467f-9939-701a6ab6d52f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-casper_2020]",
   "language": "python",
   "name": "conda-env-miniconda3-casper_2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
